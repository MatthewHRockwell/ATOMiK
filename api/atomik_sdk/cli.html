<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>atomik_sdk.cli API documentation</title>
<meta name="description" content="ATOMiK CLI Tool (atomik-gen) …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>atomik_sdk.cli</code></h1>
</header>
<section id="section-intro">
<p>ATOMiK CLI Tool (atomik-gen)</p>
<p>Command-line interface for ATOMiK schema validation, multi-language
SDK code generation, autonomous pipeline execution, performance
metrics, and domain hardware demonstrators.</p>
<h2 id="usage">Usage</h2>
<p>atomik-gen generate <schema> [options]
atomik-gen validate <schema>
atomik-gen info <schema>
atomik-gen batch <directory> [options]
atomik-gen list
atomik-gen pipeline run <schema> [options]
atomik-gen pipeline diff <schema>
atomik-gen pipeline status
atomik-gen metrics show [options]
atomik-gen metrics compare
atomik-gen metrics export &ndash;output <file>
atomik-gen demo <domain> [options]
atomik-gen &ndash;version</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="atomik_sdk.cli.build_parser"><code class="name flex">
<span>def <span class="ident">build_parser</span></span>(<span>) ‑> argparse.ArgumentParser</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_parser() -&gt; argparse.ArgumentParser:
    &#34;&#34;&#34;Build the argument parser with all subcommands.&#34;&#34;&#34;
    parser = argparse.ArgumentParser(
        prog=&#34;atomik-gen&#34;,
        description=&#34;ATOMiK schema validation and multi-language SDK code generation&#34;,
    )
    parser.add_argument(
        &#34;--version&#34;, action=&#34;version&#34;, version=f&#34;atomik-gen {__version__}&#34;
    )

    sub = parser.add_subparsers(dest=&#34;command&#34;, help=&#34;Available commands&#34;)

    # generate
    gen = sub.add_parser(&#34;generate&#34;, help=&#34;Generate SDK code from a schema&#34;)
    gen.add_argument(&#34;schema&#34;, help=&#34;Path to schema JSON file&#34;)
    gen.add_argument(&#34;--output-dir&#34;, default=&#34;generated&#34;, help=&#34;Output directory (default: generated)&#34;)
    gen.add_argument(
        &#34;--languages&#34;, nargs=&#34;+&#34;, choices=list(GENERATORS.keys()),
        help=&#34;Target languages (default: all)&#34;,
    )
    gen.add_argument(&#34;--report&#34;, help=&#34;Write JSON report to file&#34;)
    gen.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#34;store_true&#34;, help=&#34;Verbose output&#34;)

    # validate
    val = sub.add_parser(&#34;validate&#34;, help=&#34;Validate a schema (no generation)&#34;)
    val.add_argument(&#34;schema&#34;, help=&#34;Path to schema JSON file&#34;)

    # info
    inf = sub.add_parser(&#34;info&#34;, help=&#34;Show schema summary&#34;)
    inf.add_argument(&#34;schema&#34;, help=&#34;Path to schema JSON file&#34;)

    # batch
    bat = sub.add_parser(&#34;batch&#34;, help=&#34;Batch generate from a directory of schemas&#34;)
    bat.add_argument(&#34;directory&#34;, help=&#34;Directory containing schema JSON files&#34;)
    bat.add_argument(&#34;--output-dir&#34;, default=&#34;generated&#34;, help=&#34;Output directory (default: generated)&#34;)
    bat.add_argument(
        &#34;--languages&#34;, nargs=&#34;+&#34;, choices=list(GENERATORS.keys()),
        help=&#34;Target languages (default: all)&#34;,
    )
    bat.add_argument(&#34;--report&#34;, help=&#34;Write JSON report to file&#34;)
    bat.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#34;store_true&#34;, help=&#34;Verbose output&#34;)

    # list
    sub.add_parser(&#34;list&#34;, help=&#34;List available target languages&#34;)

    # -----------------------------------------------------------------------
    # pipeline subcommand group
    # -----------------------------------------------------------------------
    pipe = sub.add_parser(&#34;pipeline&#34;, help=&#34;Autonomous pipeline execution&#34;)
    pipe_sub = pipe.add_subparsers(dest=&#34;pipeline_command&#34;)

    # pipeline run
    pipe_run = pipe_sub.add_parser(&#34;run&#34;, help=&#34;Execute full pipeline&#34;)
    pipe_run.add_argument(&#34;target&#34;, help=&#34;Schema file or directory&#34;)
    pipe_run.add_argument(&#34;--output-dir&#34;, default=&#34;generated&#34;)
    pipe_run.add_argument(&#34;--languages&#34;, nargs=&#34;+&#34;, choices=list(GENERATORS.keys()))
    pipe_run.add_argument(&#34;--report&#34;, help=&#34;Write pipeline report to file&#34;)
    pipe_run.add_argument(&#34;--checkpoint&#34;, default=&#34;.atomik&#34;)
    pipe_run.add_argument(&#34;--metrics-csv&#34;, default=&#34;.atomik/metrics.csv&#34;)
    pipe_run.add_argument(&#34;--com-port&#34;, help=&#34;Serial port for hardware validation&#34;)
    pipe_run.add_argument(&#34;--token-budget&#34;, type=int, help=&#34;Maximum tokens for this run&#34;)
    pipe_run.add_argument(&#34;--sim-only&#34;, action=&#34;store_true&#34;, help=&#34;RTL simulation only&#34;)
    pipe_run.add_argument(&#34;--skip-synthesis&#34;, action=&#34;store_true&#34;)
    pipe_run.add_argument(&#34;--batch&#34;, action=&#34;store_true&#34;, help=&#34;Process directory&#34;)
    pipe_run.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#34;store_true&#34;)

    # pipeline diff
    pipe_diff = pipe_sub.add_parser(&#34;diff&#34;, help=&#34;Show what would change (dry run)&#34;)
    pipe_diff.add_argument(&#34;target&#34;, help=&#34;Schema file or directory&#34;)
    pipe_diff.add_argument(&#34;--output-dir&#34;, default=&#34;generated&#34;)
    pipe_diff.add_argument(&#34;--checkpoint&#34;, default=&#34;.atomik&#34;)
    pipe_diff.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#34;store_true&#34;)

    # pipeline status
    pipe_status = pipe_sub.add_parser(&#34;status&#34;, help=&#34;Show pipeline state&#34;)
    pipe_status.add_argument(&#34;--checkpoint&#34;, default=&#34;.atomik&#34;)

    # -----------------------------------------------------------------------
    # metrics subcommand group
    # -----------------------------------------------------------------------
    met = sub.add_parser(&#34;metrics&#34;, help=&#34;Performance metrics&#34;)
    met_sub = met.add_subparsers(dest=&#34;metrics_command&#34;)

    # metrics show
    met_show = met_sub.add_parser(&#34;show&#34;, help=&#34;Show metrics for last run&#34;)
    met_show.add_argument(&#34;--schema&#34;, help=&#34;Filter by schema name&#34;)
    met_show.add_argument(&#34;--checkpoint&#34;, default=&#34;.atomik&#34;)

    # metrics compare
    met_compare = met_sub.add_parser(&#34;compare&#34;, help=&#34;Compare metrics across schemas&#34;)
    met_compare.add_argument(&#34;--checkpoint&#34;, default=&#34;.atomik&#34;)

    # metrics export
    met_export = met_sub.add_parser(&#34;export&#34;, help=&#34;Export metrics to CSV&#34;)
    met_export.add_argument(&#34;--output&#34;, required=True, help=&#34;Output CSV file&#34;)
    met_export.add_argument(&#34;--checkpoint&#34;, default=&#34;.atomik&#34;)

    # -----------------------------------------------------------------------
    # demo subcommand
    # -----------------------------------------------------------------------
    demo = sub.add_parser(&#34;demo&#34;, help=&#34;Run domain hardware demonstrator&#34;)
    demo.add_argument(&#34;domain&#34;, help=&#34;Domain name (video, sensor, finance)&#34;)
    demo.add_argument(&#34;--com-port&#34;, help=&#34;Serial port for FPGA&#34;)
    demo.add_argument(&#34;--sim-only&#34;, action=&#34;store_true&#34;, help=&#34;Simulation only&#34;)
    demo.add_argument(&#34;--report&#34;, help=&#34;Write demo report to file&#34;)
    demo.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#34;store_true&#34;)

    # -----------------------------------------------------------------------
    # from-source subcommand
    # -----------------------------------------------------------------------
    fs = sub.add_parser(&#34;from-source&#34;, help=&#34;Generate SDK from existing source code&#34;)
    fs.add_argument(&#34;source&#34;, help=&#34;Source file path (.py, .rs, .c, .js, .v)&#34;)
    fs.add_argument(&#34;--vertical&#34;, help=&#34;Override inferred vertical category&#34;)
    fs.add_argument(&#34;--version&#34;, default=&#34;1.0.0&#34;, help=&#34;Schema version&#34;)
    fs.add_argument(&#34;--existing-schema&#34;, help=&#34;Existing schema for migration diff&#34;)
    fs.add_argument(&#34;--strict&#34;, action=&#34;store_true&#34;, help=&#34;Fail on migration warnings&#34;)
    fs.add_argument(&#34;--output-dir&#34;, default=&#34;generated&#34;)
    fs.add_argument(&#34;--languages&#34;, nargs=&#34;+&#34;, choices=list(GENERATORS.keys()))
    fs.add_argument(&#34;--report&#34;, help=&#34;Write JSON report&#34;)
    fs.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#34;store_true&#34;)

    return parser</code></pre>
</details>
<div class="desc"><p>Build the argument parser with all subcommands.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_batch"><code class="name flex">
<span>def <span class="ident">cmd_batch</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_batch(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Batch-generate SDK code from a directory of schemas.&#34;&#34;&#34;
    schemas_dir = Path(args.directory)
    if not schemas_dir.is_dir():
        print(f&#34;Error: directory not found: {schemas_dir}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    schemas = sorted(schemas_dir.glob(&#34;*.json&#34;))
    if not schemas:
        print(f&#34;Error: no JSON schemas found in {schemas_dir}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    print(f&#34;Found {len(schemas)} schema(s) in {schemas_dir}&#34;)
    print()

    all_results = []
    total_files = 0
    failures = 0

    for schema_path in schemas:
        engine = _create_engine(args.output_dir, args.languages, args.verbose)

        validation = engine.load_schema(schema_path)
        if not validation:
            print(f&#34;  {schema_path.name}: VALIDATION FAILED&#34;)
            for err in validation.errors:
                print(f&#34;    - {err}&#34;)
            all_results.append({
                &#34;schema&#34;: schema_path.name,
                &#34;success&#34;: False,
                &#34;errors&#34;: validation.errors,
                &#34;files&#34;: 0,
            })
            failures += 1
            continue

        ns = engine.extract_metadata()
        namespace = f&#34;{ns.vertical}.{ns.field}.{ns.object}&#34;
        results = engine.generate(args.languages)
        files = engine.write_output(results)

        errors = []
        lang_results = {}
        for lang, result in results.items():
            lang_results[lang] = {
                &#34;success&#34;: result.success,
                &#34;files&#34;: len(result.files),
            }
            if not result.success:
                errors.extend(result.errors)

        schema_ok = len(errors) == 0
        status = &#34;OK&#34; if schema_ok else &#34;FAIL&#34;
        print(f&#34;  {schema_path.name}: {status} ({namespace}, {len(files)} files)&#34;)

        if not schema_ok:
            failures += 1

        total_files += len(files)
        all_results.append({
            &#34;schema&#34;: schema_path.name,
            &#34;namespace&#34;: namespace,
            &#34;success&#34;: schema_ok,
            &#34;languages&#34;: lang_results,
            &#34;total_files&#34;: len(files),
            &#34;errors&#34;: errors,
        })

    print()
    print(f&#34;Processed: {len(schemas)} schema(s), {total_files} file(s), {failures} failure(s)&#34;)

    if args.report:
        _write_report(args.report, {
            &#34;schemas_dir&#34;: str(schemas_dir),
            &#34;output_dir&#34;: args.output_dir,
            &#34;total_schemas&#34;: len(schemas),
            &#34;total_files&#34;: total_files,
            &#34;failures&#34;: failures,
            &#34;results&#34;: all_results,
        })

    return EXIT_GENERATION_FAILURE if failures else EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Batch-generate SDK code from a directory of schemas.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_demo"><code class="name flex">
<span>def <span class="ident">cmd_demo</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_demo(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Run a domain hardware demonstrator.&#34;&#34;&#34;
    import re
    import shutil
    import subprocess
    import tempfile
    import time

    domain = args.domain
    valid_domains = [&#34;video&#34;, &#34;sensor&#34;, &#34;finance&#34;]

    if domain not in valid_domains:
        print(f&#34;Error: unknown domain &#39;{domain}&#39;. &#34;
              f&#34;Valid: {&#39;, &#39;.join(valid_domains)}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    project_root = Path(__file__).resolve().parent.parent.parent
    demo_dir = project_root / &#34;demos&#34; / domain

    if not demo_dir.exists():
        print(f&#34;Error: demo directory not found: {demo_dir}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    top_file = demo_dir / f&#34;{domain}_demo_top.v&#34;
    tb_file = demo_dir / f&#34;tb_{domain}_demo.v&#34;

    if not top_file.exists():
        print(f&#34;Error: demo top module not found: {top_file}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    sim_only = getattr(args, &#34;sim_only&#34;, False)
    verbose = getattr(args, &#34;verbose&#34;, False)
    t_start = time.perf_counter()

    # -- Tool detection -------------------------------------------------------
    from atomik_sdk.hardware_discovery import detect_board, find_tool

    iverilog = shutil.which(&#34;iverilog&#34;)
    vvp_cmd = shutil.which(&#34;vvp&#34;)

    has_gowin = find_tool(&#34;gw_sh&#34;) is not None
    has_programmer = find_tool(&#34;programmer_cli&#34;) is not None
    has_openfpga = find_tool(&#34;openFPGALoader&#34;) is not None

    # -- Board detection (skip when --sim-only) --------------------------------
    board_detected = False
    hardware_used = False

    if not sim_only:
        board_detected = detect_board() is not None

    mode = &#34;simulation&#34; if sim_only else &#34;auto&#34;
    print(f&#34;ATOMiK {domain.title()} Domain Demonstrator&#34;)
    print(&#34;=&#34; * 40)
    print(f&#34;  Top module: {top_file.name}&#34;)
    print(f&#34;  Testbench:  {tb_file.name if tb_file.exists() else &#39;N/A&#39;}&#34;)
    print(f&#34;  Mode:       {mode}&#34;)
    if not sim_only:
        print(f&#34;  Board:      {&#39;detected&#39; if board_detected else &#39;not detected&#39;}&#34;)
    print()

    # -- Gather Verilog source files -------------------------------------------
    common_dir = project_root / &#34;demos&#34; / &#34;common&#34;
    rtl_dir = project_root / &#34;rtl&#34;
    rtl_pll_dir = project_root / &#34;rtl&#34; / &#34;pll&#34;
    sim_stubs_dir = project_root / &#34;sim&#34; / &#34;stubs&#34;

    src_files = []
    # Stubs first (Gowin rPLL behavioural model), then PLL wrappers, RTL,
    # common modules, and finally the demo-specific sources.
    for d in [sim_stubs_dir, rtl_pll_dir, rtl_dir, common_dir, demo_dir]:
        if d.exists():
            src_files.extend(sorted(d.glob(&#34;*.v&#34;)))

    # Remove testbenches from source list
    src_files = [f for f in src_files if not f.name.startswith(&#34;tb_&#34;)]

    # -- Simulation &amp; validation tracking --------------------------------------
    success = False
    validation_level = &#34;no_rtl&#34;
    sim_tests_passed = 0
    sim_tests_total = 0
    exit_code = EXIT_SUCCESS

    if tb_file.exists():
        if iverilog and vvp_cmd:
            print(&#34;Running RTL simulation...&#34;)
            all_files = [str(f) for f in src_files] + [str(tb_file)]

            with tempfile.NamedTemporaryFile(suffix=&#34;.vvp&#34;, delete=False) as tmp:
                vvp_out = tmp.name

            compile_result = subprocess.run(
                [iverilog, &#34;-o&#34;, vvp_out] + all_files,
                capture_output=True, text=True,
                timeout=60,
            )

            if compile_result.returncode != 0:
                print(f&#34;Compilation failed:\n{compile_result.stderr}&#34;)
                exit_code = EXIT_HARDWARE_FAILURE
            else:
                sim_result = subprocess.run(
                    [vvp_cmd, vvp_out],
                    capture_output=True, text=True,
                    timeout=60,
                )

                print(sim_result.stdout)
                if sim_result.stderr and verbose:
                    print(sim_result.stderr)

                Path(vvp_out).unlink(missing_ok=True)

                # Parse pass/fail counts from the test summary block.
                # Testbenches print &#34;Passed: N&#34; and &#34;Failed: N&#34; lines.
                pass_match = re.search(
                    r&#34;Passed:\s+(\d+)&#34;, sim_result.stdout,
                )
                fail_match = re.search(
                    r&#34;Failed:\s+(\d+)&#34;, sim_result.stdout,
                )
                if pass_match:
                    sim_tests_passed = int(pass_match.group(1))
                if fail_match:
                    sim_tests_total = sim_tests_passed + int(fail_match.group(1))
                else:
                    sim_tests_total = sim_tests_passed

                # Use parsed fail count when available; fall back to
                # string heuristic only when no structured output exists.
                if fail_match:
                    has_failure = int(fail_match.group(1)) &gt; 0
                else:
                    has_failure = &#34;FAIL&#34; in sim_result.stdout.upper()
                if has_failure:
                    print(&#34;Demo simulation: FAILED&#34;)
                    validation_level = &#34;simulation_only&#34;
                    exit_code = EXIT_HARDWARE_FAILURE
                else:
                    print(&#34;Demo simulation: PASSED&#34;)
                    validation_level = &#34;simulation_only&#34;
                    success = True
        else:
            print(&#34;iverilog/vvp not found -- cannot simulate&#34;)
            exit_code = EXIT_HARDWARE_FAILURE
    else:
        print(&#34;No testbench found for this demo&#34;)

    # -- Hardware escalation (auto mode only) ----------------------------------
    if success and not sim_only and board_detected and has_gowin:
        print(&#34;Attempting synthesis (Gowin EDA)...&#34;)
        validation_level = &#34;synthesized&#34;
        hardware_used = True
        # Full synthesis + programming is handled by HardwareStage in the
        # pipeline; here we record the capability level reached.

    duration_ms = (time.perf_counter() - t_start) * 1000.0

    if args.report:
        report_data = {
            &#34;domain&#34;: domain,
            &#34;success&#34;: success,
            &#34;validation_level&#34;: validation_level,
            &#34;hardware_used&#34;: hardware_used,
            &#34;board_detected&#34;: board_detected,
            &#34;mode&#34;: mode,
            &#34;top_module&#34;: str(top_file),
            &#34;testbench&#34;: str(tb_file) if tb_file.exists() else None,
            &#34;sim_tests_passed&#34;: sim_tests_passed,
            &#34;sim_tests_total&#34;: sim_tests_total,
            &#34;duration_ms&#34;: round(duration_ms, 1),
            &#34;tools&#34;: {
                &#34;iverilog&#34;: iverilog is not None,
                &#34;gowin_eda&#34;: has_gowin,
                &#34;programmer_cli&#34;: has_programmer,
                &#34;openfpga_loader&#34;: has_openfpga,
            },
        }
        _write_report(args.report, report_data)

    return exit_code</code></pre>
</details>
<div class="desc"><p>Run a domain hardware demonstrator.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_from_source"><code class="name flex">
<span>def <span class="ident">cmd_from_source</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_from_source(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Generate SDK from existing source code (zero LLM tokens).&#34;&#34;&#34;
    source_path = Path(args.source)
    if not source_path.exists():
        print(f&#34;Error: {source_path} not found&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    from atomik_sdk.pipeline.controller import Pipeline, PipelineConfig
    from atomik_sdk.pipeline.stages.diff import DiffStage
    from atomik_sdk.pipeline.stages.extract import ExtractStage
    from atomik_sdk.pipeline.stages.generate import GenerateStage
    from atomik_sdk.pipeline.stages.hardware import HardwareStage
    from atomik_sdk.pipeline.stages.infer import InferStage
    from atomik_sdk.pipeline.stages.metrics import MetricsStage
    from atomik_sdk.pipeline.stages.migrate_check import MigrateCheckStage
    from atomik_sdk.pipeline.stages.validate import ValidateStage
    from atomik_sdk.pipeline.stages.verify import VerifyStage

    config = PipelineConfig(
        source_mode=True,
        source_path=str(source_path),
        output_dir=args.output_dir,
        languages=args.languages,
        verbose=args.verbose,
        report_path=args.report,
        existing_schema_path=getattr(args, &#34;existing_schema&#34;, None),
        fail_on_regression=getattr(args, &#34;strict&#34;, False),
        inference_overrides={
            &#34;vertical&#34;: args.vertical,
            &#34;version&#34;: args.version,
        },
    )

    pipeline = Pipeline(config)
    pipeline.register_stage(ExtractStage())
    pipeline.register_stage(InferStage())
    pipeline.register_stage(MigrateCheckStage())
    pipeline.register_stage(ValidateStage())
    pipeline.register_stage(DiffStage())
    pipeline.register_stage(GenerateStage())
    pipeline.register_stage(VerifyStage())
    pipeline.register_stage(HardwareStage())
    pipeline.register_stage(MetricsStage())

    result = pipeline.run(source_path)

    if result.success:
        print(f&#34;\nPipeline SUCCESS [{result.validation_level}]&#34;)
        print(f&#34;  Files: {result.files_generated}, &#34;
              f&#34;Lines: {result.lines_generated}, &#34;
              f&#34;Tokens: {result.total_tokens}, &#34;
              f&#34;Time: {result.total_time_ms:.0f}ms&#34;)
    else:
        print(&#34;\nPipeline FAILED&#34;, file=sys.stderr)
        for err in result.errors:
            print(f&#34;  - {err}&#34;, file=sys.stderr)

    return EXIT_SUCCESS if result.success else EXIT_GENERATION_FAILURE</code></pre>
</details>
<div class="desc"><p>Generate SDK from existing source code (zero LLM tokens).</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_generate"><code class="name flex">
<span>def <span class="ident">cmd_generate</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_generate(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Generate SDK code from a schema file.&#34;&#34;&#34;
    schema_path = Path(args.schema)
    if not schema_path.exists():
        print(f&#34;Error: schema file not found: {schema_path}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    engine = _create_engine(args.output_dir, args.languages, args.verbose)

    # Load and validate
    validation = engine.load_schema(schema_path)
    if not validation:
        print(f&#34;Validation failed for {schema_path.name}:&#34;, file=sys.stderr)
        for err in validation.errors:
            print(f&#34;  - {err}&#34;, file=sys.stderr)
        return EXIT_VALIDATION_FAILURE

    ns = engine.extract_metadata()
    namespace = f&#34;{ns.vertical}.{ns.field}.{ns.object}&#34;

    if args.verbose:
        print(f&#34;Namespace: {namespace}&#34;)

    # Generate
    results = engine.generate(args.languages)
    files = engine.write_output(results)

    # Collect errors
    errors = []
    for lang, result in results.items():
        status = &#34;OK&#34; if result.success else &#34;FAIL&#34;
        print(f&#34;  {lang}: {status} ({len(result.files)} files)&#34;)
        if not result.success:
            errors.extend(result.errors)

    print(f&#34;Generated {len(files)} file(s) in {args.output_dir}/&#34;)

    # Write report if requested
    if args.report:
        _write_report(args.report, {
            &#34;schema&#34;: schema_path.name,
            &#34;namespace&#34;: namespace,
            &#34;output_dir&#34;: args.output_dir,
            &#34;total_files&#34;: len(files),
            &#34;success&#34;: len(errors) == 0,
            &#34;languages&#34;: {
                lang: {&#34;success&#34;: r.success, &#34;files&#34;: len(r.files)}
                for lang, r in results.items()
            },
            &#34;errors&#34;: errors,
        })

    return EXIT_GENERATION_FAILURE if errors else EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Generate SDK code from a schema file.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_info"><code class="name flex">
<span>def <span class="ident">cmd_info</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_info(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Show summary information about a schema.&#34;&#34;&#34;
    schema_path = Path(args.schema)
    if not schema_path.exists():
        print(f&#34;Error: schema file not found: {schema_path}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    engine = GeneratorEngine(GeneratorConfig(validate_schemas=False))

    try:
        engine.load_schema(schema_path)
    except (ValueError, FileNotFoundError) as e:
        print(f&#34;Error: {e}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    summary = engine.get_schema_summary()
    cat = summary[&#34;catalogue&#34;]

    print(f&#34;Schema:     {schema_path.name}&#34;)
    print(f&#34;Namespace:  {cat[&#39;vertical&#39;]}.{cat[&#39;field&#39;]}.{cat[&#39;object&#39;]}&#34;)
    print(f&#34;Version:    {cat[&#39;version&#39;]}&#34;)
    print(f&#34;Hardware:   {&#39;yes&#39; if summary[&#39;has_hardware&#39;] else &#39;no&#39;}&#34;)
    print()

    print(&#34;Delta Fields:&#34;)
    for name, spec in summary[&#34;delta_fields&#34;].items():
        print(f&#34;  {name}: {spec[&#39;type&#39;]} ({spec[&#39;width&#39;]}-bit)&#34;)

    print()
    print(f&#34;Operations: {&#39;, &#39;.join(summary[&#39;operations&#39;])}&#34;)

    return EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Show summary information about a schema.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_list"><code class="name flex">
<span>def <span class="ident">cmd_list</span></span>(<span>_args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_list(_args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;List available target languages.&#34;&#34;&#34;
    print(&#34;Available target languages:&#34;)
    for lang in GENERATORS:
        print(f&#34;  {lang}&#34;)
    return EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>List available target languages.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_metrics_compare"><code class="name flex">
<span>def <span class="ident">cmd_metrics_compare</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_metrics_compare(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Compare metrics across schemas.&#34;&#34;&#34;
    from atomik_sdk.pipeline.context.checkpoint import Checkpoint
    from atomik_sdk.pipeline.metrics.reporter import MetricsReporter

    checkpoint = Checkpoint(getattr(args, &#34;checkpoint&#34;, &#34;.atomik&#34;))
    history = checkpoint.get_metrics_history()

    if not history:
        print(&#34;No metrics data available.&#34;)
        return EXIT_SUCCESS

    # Get latest run per schema
    latest: dict[str, dict] = {}
    for entry in history:
        name = entry.get(&#34;schema&#34;, &#34;unknown&#34;)
        latest[name] = entry

    reporter = MetricsReporter()
    schemas = {}
    for name, data in latest.items():
        schemas[name] = {
            &#34;time_ms&#34;: data.get(&#34;pipeline_total_time_ms&#34;, 0),
            &#34;tokens&#34;: data.get(&#34;tokens_consumed&#34;, 0),
            &#34;files&#34;: data.get(&#34;files_generated&#34;, 0),
            &#34;lines&#34;: data.get(&#34;lines_generated&#34;, 0),
            &#34;efficiency&#34;: data.get(&#34;token_efficiency_pct&#34;, 100),
        }

    table = reporter.format_comparison_table(schemas)
    print(table)

    return EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Compare metrics across schemas.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_metrics_export"><code class="name flex">
<span>def <span class="ident">cmd_metrics_export</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_metrics_export(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Export metrics history to CSV.&#34;&#34;&#34;
    from atomik_sdk.pipeline.context.checkpoint import Checkpoint

    checkpoint = Checkpoint(getattr(args, &#34;checkpoint&#34;, &#34;.atomik&#34;))
    history = checkpoint.get_metrics_history()

    if not history:
        print(&#34;No metrics data to export.&#34;)
        return EXIT_SUCCESS

    import csv
    output = Path(args.output)
    output.parent.mkdir(parents=True, exist_ok=True)

    keys = list(history[0].keys())
    with open(output, &#34;w&#34;, newline=&#34;&#34;, encoding=&#34;utf-8&#34;) as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        writer.writerows(history)

    print(f&#34;Exported {len(history)} entries to {output}&#34;)
    return EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Export metrics history to CSV.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_metrics_show"><code class="name flex">
<span>def <span class="ident">cmd_metrics_show</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_metrics_show(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Show metrics for the last pipeline run.&#34;&#34;&#34;
    from atomik_sdk.pipeline.context.checkpoint import Checkpoint
    from atomik_sdk.pipeline.metrics.reporter import MetricsReporter

    checkpoint = Checkpoint(getattr(args, &#34;checkpoint&#34;, &#34;.atomik&#34;))
    schema_name = getattr(args, &#34;schema&#34;, None)
    history = checkpoint.get_metrics_history(schema_name)

    if not history:
        print(&#34;No metrics data available. Run the pipeline first.&#34;)
        return EXIT_SUCCESS

    reporter = MetricsReporter()
    last = history[-1]
    report = reporter.format_text_report(last.get(&#34;schema&#34;, &#34;unknown&#34;), last)
    print(report)

    return EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Show metrics for the last pipeline run.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_pipeline_diff"><code class="name flex">
<span>def <span class="ident">cmd_pipeline_diff</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_pipeline_diff(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Show what the pipeline would do without executing.&#34;&#34;&#34;
    args.dry_run = True
    return cmd_pipeline_run(args)</code></pre>
</details>
<div class="desc"><p>Show what the pipeline would do without executing.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_pipeline_run"><code class="name flex">
<span>def <span class="ident">cmd_pipeline_run</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_pipeline_run(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Execute the autonomous pipeline on a schema or directory.&#34;&#34;&#34;
    target = Path(args.target)
    if not target.exists():
        print(f&#34;Error: not found: {target}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    pipeline = _create_pipeline(args)

    if target.is_dir() or getattr(args, &#34;batch&#34;, False):
        results = pipeline.run_batch(target)
        failures = sum(1 for r in results if not r.success)
        total = len(results)
        print(f&#34;\nPipeline complete: {total} schema(s), {failures} failure(s)&#34;)
        for r in results:
            status = &#34;OK&#34; if r.success else &#34;FAIL&#34;
            print(f&#34;  {r.schema}: {status} [{r.validation_level}] &#34;
                  f&#34;({r.files_generated} files, {r.total_tokens} tokens, &#34;
                  f&#34;{r.total_time_ms:.0f}ms)&#34;)
        return EXIT_GENERATION_FAILURE if failures else EXIT_SUCCESS
    else:
        result = pipeline.run(target)
        if result.success:
            print(f&#34;\nPipeline SUCCESS [{result.validation_level}]&#34;)
            print(f&#34;  Files: {result.files_generated}, &#34;
                  f&#34;Lines: {result.lines_generated}, &#34;
                  f&#34;Tokens: {result.total_tokens}, &#34;
                  f&#34;Time: {result.total_time_ms:.0f}ms&#34;)
        else:
            print(&#34;\nPipeline FAILED&#34;, file=sys.stderr)
            for err in result.errors:
                print(f&#34;  - {err}&#34;, file=sys.stderr)
        return EXIT_SUCCESS if result.success else EXIT_GENERATION_FAILURE</code></pre>
</details>
<div class="desc"><p>Execute the autonomous pipeline on a schema or directory.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_pipeline_status"><code class="name flex">
<span>def <span class="ident">cmd_pipeline_status</span></span>(<span>_args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_pipeline_status(_args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Show pipeline status from checkpoint.&#34;&#34;&#34;
    from atomik_sdk.pipeline.context.checkpoint import Checkpoint

    checkpoint_dir = getattr(_args, &#34;checkpoint&#34;, &#34;.atomik&#34;)
    checkpoint = Checkpoint(checkpoint_dir)
    state = checkpoint.to_dict()

    schemas = state.get(&#34;schemas&#34;, {})
    history = state.get(&#34;metrics_history&#34;, [])

    print(&#34;ATOMiK Pipeline Status&#34;)
    print(&#34;=&#34; * 40)
    print(f&#34;  Checkpoint:    {checkpoint_dir}&#34;)
    print(f&#34;  Last updated:  {state.get(&#39;last_updated&#39;, &#39;never&#39;)}&#34;)
    print(f&#34;  Schemas:       {len(schemas)}&#34;)
    print(f&#34;  History:       {len(history)} run(s)&#34;)
    print()

    if schemas:
        print(&#34;Registered Schemas:&#34;)
        for name, info in schemas.items():
            gen = info.get(&#34;last_generated&#34;, &#34;never&#34;)
            print(f&#34;  {name}: generated {gen}&#34;)
        print()

    if history:
        last = history[-1]
        print(&#34;Last Run:&#34;)
        print(f&#34;  Schema:    {last.get(&#39;schema&#39;, &#39;unknown&#39;)}&#34;)
        print(f&#34;  Timestamp: {last.get(&#39;timestamp&#39;, &#39;unknown&#39;)}&#34;)
        print(f&#34;  Tokens:    {last.get(&#39;tokens_consumed&#39;, 0)}&#34;)
        print(f&#34;  Files:     {last.get(&#39;files_generated&#39;, 0)}&#34;)

    return EXIT_SUCCESS</code></pre>
</details>
<div class="desc"><p>Show pipeline status from checkpoint.</p></div>
</dd>
<dt id="atomik_sdk.cli.cmd_validate"><code class="name flex">
<span>def <span class="ident">cmd_validate</span></span>(<span>args: argparse.Namespace) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cmd_validate(args: argparse.Namespace) -&gt; int:
    &#34;&#34;&#34;Validate a schema file without generating code.&#34;&#34;&#34;
    schema_path = Path(args.schema)
    if not schema_path.exists():
        print(f&#34;Error: schema file not found: {schema_path}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR

    validator = SchemaValidator()
    result = validator.validate_file(schema_path)

    print(f&#34;{schema_path.name}: {result}&#34;)

    if result.errors:
        for err in result.errors:
            print(f&#34;  ERROR: {err}&#34;)

    if result.warnings:
        for warn in result.warnings:
            print(f&#34;  WARN:  {warn}&#34;)

    return EXIT_SUCCESS if result.valid else EXIT_VALIDATION_FAILURE</code></pre>
</details>
<div class="desc"><p>Validate a schema file without generating code.</p></div>
</dd>
<dt id="atomik_sdk.cli.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>) ‑> int</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main() -&gt; int:
    &#34;&#34;&#34;Entry point for the atomik-gen CLI.&#34;&#34;&#34;
    parser = build_parser()
    args = parser.parse_args()

    if args.command is None:
        if sys.stdin.isatty():
            from atomik_sdk.terminal import main as terminal_main

            terminal_main()
            return EXIT_SUCCESS
        parser.print_help()
        return EXIT_SUCCESS

    # Handle subcommand groups
    if args.command == &#34;pipeline&#34;:
        pipeline_commands = {
            &#34;run&#34;: cmd_pipeline_run,
            &#34;diff&#34;: cmd_pipeline_diff,
            &#34;status&#34;: cmd_pipeline_status,
        }
        subcmd = getattr(args, &#34;pipeline_command&#34;, None)
        if subcmd is None:
            parser.parse_args([&#34;pipeline&#34;, &#34;--help&#34;])
            return EXIT_SUCCESS
        return pipeline_commands[subcmd](args)

    if args.command == &#34;metrics&#34;:
        metrics_commands = {
            &#34;show&#34;: cmd_metrics_show,
            &#34;compare&#34;: cmd_metrics_compare,
            &#34;export&#34;: cmd_metrics_export,
        }
        subcmd = getattr(args, &#34;metrics_command&#34;, None)
        if subcmd is None:
            parser.parse_args([&#34;metrics&#34;, &#34;--help&#34;])
            return EXIT_SUCCESS
        return metrics_commands[subcmd](args)

    commands = {
        &#34;generate&#34;: cmd_generate,
        &#34;validate&#34;: cmd_validate,
        &#34;info&#34;: cmd_info,
        &#34;batch&#34;: cmd_batch,
        &#34;list&#34;: cmd_list,
        &#34;demo&#34;: cmd_demo,
        &#34;from-source&#34;: cmd_from_source,
    }

    try:
        return commands[args.command](args)
    except Exception as e:
        print(f&#34;Error: {e}&#34;, file=sys.stderr)
        return EXIT_FILE_ERROR</code></pre>
</details>
<div class="desc"><p>Entry point for the atomik-gen CLI.</p></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="atomik_sdk" href="index.html">atomik_sdk</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="atomik_sdk.cli.build_parser" href="#atomik_sdk.cli.build_parser">build_parser</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_batch" href="#atomik_sdk.cli.cmd_batch">cmd_batch</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_demo" href="#atomik_sdk.cli.cmd_demo">cmd_demo</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_from_source" href="#atomik_sdk.cli.cmd_from_source">cmd_from_source</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_generate" href="#atomik_sdk.cli.cmd_generate">cmd_generate</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_info" href="#atomik_sdk.cli.cmd_info">cmd_info</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_list" href="#atomik_sdk.cli.cmd_list">cmd_list</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_metrics_compare" href="#atomik_sdk.cli.cmd_metrics_compare">cmd_metrics_compare</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_metrics_export" href="#atomik_sdk.cli.cmd_metrics_export">cmd_metrics_export</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_metrics_show" href="#atomik_sdk.cli.cmd_metrics_show">cmd_metrics_show</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_pipeline_diff" href="#atomik_sdk.cli.cmd_pipeline_diff">cmd_pipeline_diff</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_pipeline_run" href="#atomik_sdk.cli.cmd_pipeline_run">cmd_pipeline_run</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_pipeline_status" href="#atomik_sdk.cli.cmd_pipeline_status">cmd_pipeline_status</a></code></li>
<li><code><a title="atomik_sdk.cli.cmd_validate" href="#atomik_sdk.cli.cmd_validate">cmd_validate</a></code></li>
<li><code><a title="atomik_sdk.cli.main" href="#atomik_sdk.cli.main">main</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
